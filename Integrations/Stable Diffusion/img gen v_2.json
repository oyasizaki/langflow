{"id":"47f45b9c-f3a4-4fe1-b25c-d001613f4317","data":{"nodes":[{"id":"OllamaLLM-qR5hy","type":"genericNode","position":{"x":258,"y":-35},"data":{"type":"OllamaLLM","node":{"template":{"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Base URL","advanced":false,"dynamic":false,"info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.","title_case":true,"value":"http://192.168.0.101:11434"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain.llms.base import BaseLLM\nfrom langchain_community.llms.ollama import Ollama\n\nfrom langflow import CustomComponent\n\n\nclass OllamaLLM(CustomComponent):\n    display_name = \"Ollama\"\n    description = \"Local LLM with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate influencing the algorithm's response to feedback.\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls balance between coherence and diversity.\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating the next token.\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation.\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation.\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"Sets how far back the model looks to prevent repetition.\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling to reduce impact of less probable tokens.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K for reducing nonsense generation.\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"int\",\n                \"info\": \"Works with top-k to control diversity of generated text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        temperature: Optional[float],\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        num_thread: Optional[int] = None,\n        repeat_last_n: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        tfs_z: Optional[float] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseLLM:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        try:\n            llm = Ollama(\n                base_url=base_url,\n                model=model,\n                mirostat=mirostat_value,\n                mirostat_eta=mirostat_eta,\n                mirostat_tau=mirostat_tau,\n                num_ctx=num_ctx,\n                num_gpu=num_gpu,\n                num_thread=num_thread,\n                repeat_last_n=repeat_last_n,\n                repeat_penalty=repeat_penalty,\n                temperature=temperature,\n                stop=stop,\n                tfs_z=tfs_z,\n                top_k=top_k,\n                top_p=top_p,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama.\") from e\n\n        return llm\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":false,"dynamic":true,"info":"","title_case":true},"mirostat":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Disabled","fileTypes":[],"file_path":"","password":false,"options":["Disabled","Mirostat","Mirostat 2.0"],"name":"mirostat","display_name":"Mirostat","advanced":true,"dynamic":false,"info":"Enable/disable Mirostat sampling for controlling perplexity.","title_case":true},"mirostat_eta":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_eta","display_name":"Mirostat Eta","advanced":true,"dynamic":false,"info":"Learning rate influencing the algorithm's response to feedback.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"mirostat_tau":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_tau","display_name":"Mirostat Tau","advanced":true,"dynamic":false,"info":"Controls balance between coherence and diversity.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"model":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama3","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"Refer to https://ollama.ai/library for more models.","title_case":true},"num_ctx":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_ctx","display_name":"Context Window Size","advanced":true,"dynamic":false,"info":"Size of the context window for generating the next token.","title_case":true},"num_gpu":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_gpu","display_name":"Number of GPUs","advanced":true,"dynamic":false,"info":"Number of GPUs to use for computation.","title_case":true},"num_thread":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_thread","display_name":"Number of Threads","advanced":true,"dynamic":false,"info":"Number of threads to use during computation.","title_case":true},"repeat_last_n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_last_n","display_name":"Repeat Last N","advanced":true,"dynamic":false,"info":"Sets how far back the model looks to prevent repetition.","title_case":true},"repeat_penalty":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_penalty","display_name":"Repeat Penalty","advanced":true,"dynamic":false,"info":"Penalty for repetitions in generated text.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"stop":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"stop","display_name":"Stop Tokens","advanced":true,"dynamic":false,"info":"List of tokens to signal the model to stop generating text.","title_case":true},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.8,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Controls the creativity of model responses.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"tfs_z":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tfs_z","display_name":"TFS Z","advanced":true,"dynamic":false,"info":"Tail free sampling to reduce impact of less probable tokens.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":true,"dynamic":false,"info":"Limits token selection to top K for reducing nonsense generation.","title_case":true},"top_p":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_p","display_name":"Top P","advanced":true,"dynamic":false,"info":"Works with top-k to control diversity of generated text.","title_case":true},"_type":"CustomComponent"},"description":"Local LLM with Ollama.","base_classes":["BaseLLM","BaseLanguageModel"],"display_name":"Ollama","documentation":"","custom_fields":{"base_url":null,"model":null,"temperature":null,"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"num_ctx":null,"num_gpu":null,"num_thread":null,"repeat_last_n":null,"repeat_penalty":null,"stop":null,"tfs_z":null,"top_k":null,"top_p":null},"output_types":["BaseLLM"],"field_formatters":{},"beta":true},"id":"OllamaLLM-qR5hy"},"selected":false,"width":384,"height":555,"dragging":false},{"id":"Tool-SaVWU","type":"genericNode","position":{"x":241,"y":599},"data":{"type":"Tool","node":{"template":{"func":{"type":"Callable","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"func","advanced":false,"dynamic":false,"info":"","title_case":true},"description":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"Image generation","fileTypes":[],"file_path":"","password":false,"name":"description","advanced":false,"dynamic":false,"info":"","title_case":true},"name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"AUTOMATIC1111","fileTypes":[],"file_path":"","password":false,"name":"name","advanced":false,"dynamic":false,"info":"","title_case":true},"return_direct":{"type":"bool","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"return_direct","advanced":false,"dynamic":false,"info":"","title_case":true},"_type":"Tool"},"description":"Converts a chain, agent or function into a tool.","base_classes":["Tool","BaseTool"],"display_name":"Tool","documentation":"","custom_fields":{},"output_types":[],"field_formatters":{},"beta":false},"id":"Tool-SaVWU"},"selected":false,"width":384,"height":491,"dragging":false},{"id":"PythonFunction-Fjp4v","type":"genericNode","position":{"x":-222,"y":674.51875},"data":{"type":"PythonFunction","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import requests\r\nimport base64\r\nimport webbrowser\r\nimport os\r\nimport tempfile\r\nfrom PIL import Image, PngImagePlugin\r\nimport io\r\n\r\ndef generate_image(input: str, steps: int = 5) -> None:\r\n    \"\"\"\r\n    Generates an image based on the provided prompt and steps using the specified API.\r\n\r\n    Args:\r\n    prompt (str): The text prompt for generating the image.\r\n    steps (int): The number of steps for the image generation process.\r\n\r\n    Returns:\r\n    None\r\n    \"\"\"\r\n    url = \"http://192.168.0.101:7860\"\r\n    payload = {\r\n        \"prompt\": input,\r\n        \"steps\": 5\r\n    }\r\n\r\n    response = requests.post(url=f'{url}/sdapi/v1/txt2img', json=payload)\r\n    response.raise_for_status()\r\n    r = response.json()\r\n\r\n    for i in r['images']:\r\n        image = Image.open(io.BytesIO(base64.b64decode(i.split(\",\", 1)[0])))\r\n\r\n        png_payload = {\r\n            \"image\": \"data:image/png;base64,\" + i\r\n        }\r\n        response2 = requests.post(url=f'{url}/sdapi/v1/png-info', json=png_payload)\r\n        response2.raise_for_status()\r\n\r\n        pnginfo = PngImagePlugin.PngInfo()\r\n        pnginfo.add_text(\"parameters\", response2.json().get(\"info\"))\r\n        \r\n        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_file:\r\n            image.save(temp_file, pnginfo=pnginfo)\r\n            temp_file_path = temp_file.name\r\n        \r\n        # Open the image in the web browser\r\n        webbrowser.open(f'file://{temp_file_path}')\r\n        \r\n        # Return the path to the temporary file\r\n        return temp_file_path\r\n\r\n\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":false,"dynamic":false,"info":"","title_case":true},"_type":"PythonFunction"},"description":"Python function to be executed.","base_classes":["Callable"],"display_name":"PythonFunction","documentation":"","custom_fields":{},"output_types":[],"field_formatters":{},"beta":false},"id":"PythonFunction-Fjp4v"},"selected":true,"width":384,"height":281,"dragging":false},{"id":"ZeroShotAgent-SgMQz","type":"genericNode","position":{"x":853,"y":525.51875},"data":{"type":"ZeroShotAgent","node":{"template":{"callback_manager":{"type":"BaseCallbackManager","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"callback_manager","advanced":false,"dynamic":false,"info":"","title_case":true},"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"password":false,"name":"llm","advanced":false,"dynamic":false,"info":"","title_case":true},"output_parser":{"type":"AgentOutputParser","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"output_parser","advanced":false,"dynamic":false,"info":"","title_case":true},"tools":{"type":"BaseTool","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"password":false,"name":"tools","advanced":false,"dynamic":false,"info":"","title_case":true},"format_instructions":{"type":"str","required":false,"placeholder":"","list":false,"show":false,"multiline":true,"value":"Use the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question","fileTypes":[],"password":false,"name":"format_instructions","advanced":false,"dynamic":false,"info":"","title_case":true},"input_variables":{"type":"str","required":false,"placeholder":"","list":true,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"input_variables","advanced":false,"dynamic":false,"info":"","title_case":true},"prefix":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"Answer the following questions as best you can. You have access to the following tools:","fileTypes":[],"password":false,"name":"prefix","advanced":false,"dynamic":false,"info":"","title_case":true},"suffix":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"Begin!\n\nQuestion: {input}\nThought:{agent_scratchpad}","fileTypes":[],"password":false,"name":"suffix","advanced":false,"dynamic":false,"info":"","title_case":true},"_type":"ZeroShotAgent"},"description":"Construct an agent from an LLM and tools.","base_classes":["ZeroShotAgent","Agent","BaseSingleActionAgent","Callable"],"display_name":"ZeroShotAgent","documentation":"https://python.langchain.com/docs/modules/agents/how_to/custom_mrkl_agent","custom_fields":{},"output_types":[],"field_formatters":{},"beta":false},"id":"ZeroShotAgent-SgMQz"},"selected":false,"width":384,"height":463,"dragging":false}],"edges":[{"source":"PythonFunction-Fjp4v","target":"Tool-SaVWU","sourceHandle":"{œbaseClassesœ:[œCallableœ],œdataTypeœ:œPythonFunctionœ,œidœ:œPythonFunction-Fjp4vœ}","targetHandle":"{œfieldNameœ:œfuncœ,œidœ:œTool-SaVWUœ,œinputTypesœ:null,œtypeœ:œCallableœ}","id":"reactflow__edge-PythonFunction-Fjp4v{œbaseClassesœ:[œCallableœ],œdataTypeœ:œPythonFunctionœ,œidœ:œPythonFunction-Fjp4vœ}-Tool-SaVWU{œfieldNameœ:œfuncœ,œidœ:œTool-SaVWUœ,œinputTypesœ:null,œtypeœ:œCallableœ}","data":{"targetHandle":{"fieldName":"func","id":"Tool-SaVWU","inputTypes":null,"type":"Callable"},"sourceHandle":{"baseClasses":["Callable"],"dataType":"PythonFunction","id":"PythonFunction-Fjp4v"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 ","animated":false,"selected":false},{"source":"Tool-SaVWU","target":"ZeroShotAgent-SgMQz","sourceHandle":"{œbaseClassesœ:[œToolœ,œBaseToolœ],œdataTypeœ:œToolœ,œidœ:œTool-SaVWUœ}","targetHandle":"{œfieldNameœ:œtoolsœ,œidœ:œZeroShotAgent-SgMQzœ,œinputTypesœ:null,œtypeœ:œBaseToolœ}","id":"reactflow__edge-Tool-SaVWU{œbaseClassesœ:[œToolœ,œBaseToolœ],œdataTypeœ:œToolœ,œidœ:œTool-SaVWUœ}-ZeroShotAgent-SgMQz{œfieldNameœ:œtoolsœ,œidœ:œZeroShotAgent-SgMQzœ,œinputTypesœ:null,œtypeœ:œBaseToolœ}","data":{"targetHandle":{"fieldName":"tools","id":"ZeroShotAgent-SgMQz","inputTypes":null,"type":"BaseTool"},"sourceHandle":{"baseClasses":["Tool","BaseTool"],"dataType":"Tool","id":"Tool-SaVWU"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 ","animated":false,"selected":false},{"source":"OllamaLLM-qR5hy","target":"ZeroShotAgent-SgMQz","sourceHandle":"{œbaseClassesœ:[œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-qR5hyœ}","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œZeroShotAgent-SgMQzœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","id":"reactflow__edge-OllamaLLM-qR5hy{œbaseClassesœ:[œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-qR5hyœ}-ZeroShotAgent-SgMQz{œfieldNameœ:œllmœ,œidœ:œZeroShotAgent-SgMQzœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"ZeroShotAgent-SgMQz","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLLM","BaseLanguageModel"],"dataType":"OllamaLLM","id":"OllamaLLM-qR5hy"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 ","animated":false,"selected":false}],"viewport":{"x":252.52323232323238,"y":48.44040404040405,"zoom":0.4541414141414141}},"description":"Your Passport to Linguistic Landscapes.","name":"img gen v_2","last_tested_version":"0.6.19","is_component":false}